{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a9985d",
   "metadata": {},
   "source": [
    "### Text splitting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd043fcc",
   "metadata": {},
   "source": [
    "## LangChain's TextSplitter turns a list of documents (or long strings) into smaller, overlapping text chunks\n",
    "Common Classes in langchain.text_splitter\n",
    "| Splitter Class                   | Use Case                                             |\n",
    "| -------------------------------- | ---------------------------------------------------- |\n",
    "| `RecursiveCharacterTextSplitter` | Smart default – splits by paragraphs, then sentences |\n",
    "| `CharacterTextSplitter`          | Splits based on a character (like \"\\n\" or space)     |\n",
    "| `TokenTextSplitter`              | Splits by tokens (based on tokenizer like tiktoken)  |\n",
    "| `MarkdownTextSplitter`           | Specialized for Markdown formatting                  |\n",
    "| `SpacyTextSplitter`              | Uses spaCy for sentence-based splitting              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ceca25",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "#### Under the Hood: Recursive Splitting\n",
    "RecursiveCharacterTextSplitter tries to split on large natural boundaries like:\n",
    "\n",
    "Paragraphs (\\n\\n)\n",
    "\n",
    "Sentences (.)\n",
    "\n",
    "Words ( )\n",
    "\n",
    "Characters\n",
    "\n",
    "It recursively backs off to smaller boundaries if needed.\n",
    "\n",
    "#### Why Overlap?\n",
    "Overlap helps the LLM retain context across chunks. For example, if a paragraph spans two chunks, the overlap ensures both chunks include enough of it to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99e6bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "LangChain is a framework designed to help developers build applications powered by language models. It provides tools and abstractions for working with large language models like GPT-4.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "One of the core challenges in using LLMs is managing the context window â€” models can only take in a limited number of tokens. LangChain solves this by offering tools like document loaders, text\n",
      "\n",
      "--- Chunk 3 ---\n",
      "\n",
      "like document loaders, text splitters, and memory modules.\n",
      "\n",
      "--- Chunk 4 ---\n",
      "\n",
      "Text splitters are particularly useful when working with long documents. They break down text into chunks that fit within the LLMâ€™s context window, optionally with overlapping content for\n",
      "\n",
      "--- Chunk 5 ---\n",
      "\n",
      "with overlapping content for continuity.\n",
      "\n",
      "--- Chunk 6 ---\n",
      "\n",
      "LangChain also supports retrieval-based question answering (RAG), where external documents are converted into embeddings, stored in a vector database, and queried based on similarity to a user's\n",
      "\n",
      "--- Chunk 7 ---\n",
      "\n",
      "on similarity to a user's question.\n",
      "\n",
      "--- Chunk 8 ---\n",
      "\n",
      "With LangChain, developers can build chatbots, summarization tools, document Q&A apps, and more â€” all with minimal boilerplate.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"example.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad4ad9",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter\n",
    "Splits based on a character (like \"\\n\" or space) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "064799e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "LangChain is a framework designed to help developers build applications powered by language models. It provides tools and abstractions for working with large language models like GPT-4.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "One of the core challenges in using LLMs is managing the context window â€” models can only take in a limited number of tokens. LangChain solves this by offering tools like document loaders, text splitters, and memory modules.\n",
      "\n",
      "--- Chunk 3 ---\n",
      "\n",
      "Text splitters are particularly useful when working with long documents. They break down text into chunks that fit within the LLMâ€™s context window, optionally with overlapping content for continuity.\n",
      "\n",
      "--- Chunk 4 ---\n",
      "\n",
      "LangChain also supports retrieval-based question answering (RAG), where external documents are converted into embeddings, stored in a vector database, and queried based on similarity to a user's question.\n",
      "\n",
      "--- Chunk 5 ---\n",
      "\n",
      "With LangChain, developers can build chatbots, summarization tools, document Q&A apps, and more â€” all with minimal boilerplate.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "loader = TextLoader(\"example.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42568620",
   "metadata": {},
   "source": [
    "### TokenTextSplitter\n",
    "Useful when you want chunk sizes to match LLM token limits\n",
    "\n",
    "Helps avoid exceeding model input size\n",
    "\n",
    "Works with tokenizers like tiktoken (used by OpenAI models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa331996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "LangChain is a framework designed to help developers build applications powered by language models. It provides tools and abstractions for working with large language models like GPT-4.\n",
      "\n",
      "One of the core challenges in using LLMs is managing the context window â€” models can only take in a limited number of tokens. LangChain solves this by offering tools like document loaders, text splitters, and memory modules.\n",
      "\n",
      "Text splitters are particularly useful when working with long documents\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      " splitters, and memory modules.\n",
      "\n",
      "Text splitters are particularly useful when working with long documents. They break down text into chunks that fit within the LLMâ€™s context window, optionally with overlapping content for continuity.\n",
      "\n",
      "LangChain also supports retrieval-based question answering (RAG), where external documents are converted into embeddings, stored in a vector database, and queried based on similarity to a user's question.\n",
      "\n",
      "With LangChain, developers can build chat\n",
      "\n",
      "--- Chunk 3 ---\n",
      "\n",
      "ied based on similarity to a user's question.\n",
      "\n",
      "With LangChain, developers can build chatbots, summarization tools, document Q&A apps, and more â€” all with minimal boilerplate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "loader = TextLoader(\"example.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32e36f",
   "metadata": {},
   "source": [
    "### MarkdownTextSplitter\n",
    "which is specifically designed to split Markdown documents based on their headings and structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "835c624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "# LangChain Overview\n",
      "\n",
      "LangChain is a framework to build LLM-powered applications.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Document loading\n",
      "- Text splitting\n",
      "- Embedding and vector search\n",
      "\n",
      "## Use Cases\n",
      "\n",
      "### Question Answering\n",
      "\n",
      "Build Q&A bots over your documents.\n",
      "\n",
      "### Summarization\n",
      "\n",
      "Summarize long texts using LLMs.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "# Conclusion\n",
      "\n",
      "LangChain simplifies building LLM pipelines.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load the markdown file as a single document\n",
    "loader = TextLoader(\"markdown_example.md\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize Markdown splitter\n",
    "splitter = MarkdownTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "\n",
    "# Split the document\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "# Print chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc4a5",
   "metadata": {},
   "source": [
    "### SpacyTextSplitter\n",
    "Splits text at linguistic boundaries (sentences), not characters or fixed lengths,\n",
    "Preserves natural language flow, improving LLM understanding,\n",
    "Useful for tasks like summarization, translation, Q&A, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "216c67bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 90, which is longer than the specified 30\n",
      "Created a chunk of size 74, which is longer than the specified 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "LangChain is an open-source framework to build applications using large language models.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "It provides utilities for text loading, splitting, retrieval, and memory.\n",
      "\n",
      "--- Chunk 3 ---\n",
      "This helps developers create powerful AI tools with minimal effort.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "\n",
    "# Sample long text\n",
    "text = \"\"\"\n",
    "LangChain is an open-source framework to build applications using large language models.\n",
    "It provides utilities for text loading, splitting, retrieval, and memory.\n",
    "This helps developers create powerful AI tools with minimal effort.\n",
    "\"\"\"\n",
    "\n",
    "# Create a SpacyTextSplitter\n",
    "splitter = SpacyTextSplitter(chunk_size=30, chunk_overlap=5)\n",
    "\n",
    "# Split the text (returns list of strings)\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Show the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d5207",
   "metadata": {},
   "source": [
    "### HTMLHeaderTextSplitter\n",
    "\n",
    "Splits HTML content based on logical sections\\n\n",
    "Retains structure for summarization, indexing, or retrieval\\n\n",
    "Great for crawling and analyzing web pages with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecfaef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview'}\n",
      "LangChain Overview\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview'}\n",
      "LangChain helps build LLM-based applications.\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Key Features'}\n",
      "Key Features\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Key Features'}\n",
      "It supports document loading, splitting, and retrieval.\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Use Cases'}\n",
      "Use Cases\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Use Cases', 'Header 3': 'Chatbots'}\n",
      "Chatbots\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Use Cases', 'Header 3': 'Chatbots'}\n",
      "Build context-aware chatbots over custom data.\n",
      "\n",
      "--- Chunk 8 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Use Cases', 'Header 3': 'Summarization'}\n",
      "Summarization\n",
      "\n",
      "--- Chunk 9 ---\n",
      "Metadata: {'Header 1': 'LangChain Overview', 'Header 2': 'Use Cases', 'Header 3': 'Summarization'}\n",
      "Generate summaries from long documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "\n",
    "# Define the header tags you want to split on\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\")\n",
    "]\n",
    "\n",
    "# Sample HTML as string\n",
    "html_string = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <h1>LangChain Overview</h1>\n",
    "    <p>LangChain helps build LLM-based applications.</p>\n",
    "    <h2>Key Features</h2>\n",
    "    <p>It supports document loading, splitting, and retrieval.</p>\n",
    "    <h2>Use Cases</h2>\n",
    "    <h3>Chatbots</h3>\n",
    "    <p>Build context-aware chatbots over custom data.</p>\n",
    "    <h3>Summarization</h3>\n",
    "    <p>Generate summaries from long documents.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the HTML splitter\n",
    "splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Split the HTML into LangChain documents\n",
    "docs = splitter.split_text(html_string)\n",
    "\n",
    "# Print results\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739ce07",
   "metadata": {},
   "source": [
    "### RecursiveJsonSplitter or JSONStringSplitter\n",
    "| Splitter                | Description                                           |\n",
    "| ----------------------- | ----------------------------------------------------- |\n",
    "| `RecursiveJsonSplitter` | Splits deeply nested Python dicts/lists intelligently |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef70a7",
   "metadata": {},
   "source": [
    "### RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81c18146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "{'title': 'LangChain Overview', 'sections': [{'heading': 'Introduction', 'content': 'LangChain helps you build LLM-powered apps.'}, {'heading': 'Features', 'content': 'It supports document loaders, text splitters, and retrieval.'}, {'heading': 'Conclusion', 'content': 'LangChain simplifies working with language models.'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveJsonSplitter\n",
    "# Example JSON data (Python dict format)\n",
    "json_data = {\n",
    "    \"title\": \"LangChain Overview\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"heading\": \"Introduction\",\n",
    "            \"content\": \"LangChain helps you build LLM-powered apps.\"\n",
    "        },\n",
    "        {\n",
    "            \"heading\": \"Features\",\n",
    "            \"content\": \"It supports document loaders, text splitters, and retrieval.\"\n",
    "        },\n",
    "        {\n",
    "            \"heading\": \"Conclusion\",\n",
    "            \"content\": \"LangChain simplifies working with language models.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create splitter\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=100) \n",
    "# Split JSON into chunks (returns list of dicts)\n",
    "chunks = splitter.split_json(json_data)\n",
    "\n",
    "# Show chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
